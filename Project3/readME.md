
 ## **Project3: Extract Transform Load Pipelines for extracting data to another location**

*Purpose*
Create an ETL Pipeline to transfer data from multiple data streams

*Tools Used*
- Pyspark
- PostgreSQL

**Task:**
1. Load the data scientist job market dataset and us stocks datasets from the local computer.
2. Read the data with pyspark
3. Read the alldata.csv from the data scientist datasets
4. Selecting users from only one country.
5. Joining the two distinct datasets.
6. Creating a temporary table using SQL to generate output.
7. Connecting to postgresql using the postgresql driver